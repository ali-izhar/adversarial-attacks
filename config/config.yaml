# Configuration for adversarial attack method evaluation

##############################################################
# ALL CONFIGS BELOW ARE DEFAULT VALUES THAT CAN BE OVERRIDEN 
# IN THE DEMO.PY SCRIPT THROUGH COMMAND LINE ARGUMENTS
##############################################################

# Dataset configuration
dataset:
  name: "imagenet"
  num_images: 10    # Number of images to evaluate per model
  image_dir: "data"

# Model configuration
models:
  - "resnet18"     # Standard baseline model
  - "resnet50"     # Deeper variant of ResNet
  - "vgg16"        # Standard CNN architecture
  - "efficientnet" # Modern efficient architecture
  - "mobilenet"    # Lightweight architecture

# Evaluation parameters
evaluation:
  save_results: true
  output_dir: "results"

# Attack method configuration
attack:
  method: "FGSM"  # Options: FGSM, FFGSM, DeepFool, CW, PGD, CG, LBFGS
  norm_types:
    - "Linf" 
    - "L2"
  
  # Method-specific parameters
  params:

  # BASELINE ATTACKS
  # ------------------
    FGSM:
      untargeted:
        loss_fn: "cross_entropy"
        eps_values:
          Linf: [4/255, 8/255]  # Standard values from Goodfellow et al. (2014)
          L2: [0.5, 1.0]        # Standard values for L2 attacks
      targeted:
        loss_fn: "cross_entropy"
        eps_values:
          Linf: [16/255, 32/255]  # Larger values needed for targeted attacks
          L2: [2.0, 3.0]          # Larger perturbations for targeted attacks

    FFGSM:
      untargeted:
        loss_fn: "cross_entropy"
        alpha_linf: 0.04  # 1.25 × 8/255 
        alpha_l2: 0.625   # 1.25 × 0.5 (the L2 epsilon)
        eps_values:
          Linf: [8/255]   # Should achieve ~87.5% success with SSIM > 0.8
          L2: [0.5]       # Should achieve good success with SSIM > 0.7
      targeted:
        loss_fn: "cross_entropy"
        alpha_linf: 0.02  # 1.25 × 16/255
        alpha_l2: 2.5     # 1.25 × 2.0
        eps_values:
          Linf: [16/255, 32/255]  # Larger epsilon for targeted attacks
          L2: [2.0, 3.0]          # Larger epsilon for targeted attacks
    
    DeepFool:
      # DeepFool is typically untargeted only
      untargeted:
        num_classes: 1000          # ImageNet class count
        overshoot_values: [0.02]   # Standard value from Moosavi-Dezfooli et al. (2016)
        steps: 50                  # Reduced from 100 as DeepFool converges quickly
        early_stopping: true       # Enable early stopping to improve efficiency
        top_k_classes: 10          # Only consider top-k classes for efficiency
    
    CW:
      untargeted:
        confidence_values: [0.0]   # Correct
        c_init: 1.0                # Initial c value
        steps: 1000                # Practical compromise (more is better)
        learning_rate: 0.01        # Standard learning rate from original paper
        abort_early: true          # Enable early stopping for efficiency
      targeted:
        confidence_values: [5.0, 20.0]  # Multiple options to try
        c_init: 10.0               # Higher c value for targeted attacks
        steps: 1000                # More steps for targeted
        learning_rate: 0.01        # Same learning rate
        abort_early: true          # Enable early stopping for efficiency
    

    # ADVERSARIAL ATTACKS
    # ---------------------
    CG:
      untargeted:
        loss_fn: "cross_entropy"        # Loss function used
        steps: 40                       # Number of iterations
        alpha: 0.05                     # Step size for L2 (alpha = eps / (steps / 4) heuristic)
        alpha_multiplier: 40.0          # Alpha multiplier for Linf (gives ~2/255 step size)
        beta_method: "PR"               # Beta calculation: 'PR' (Polak-Ribière) or 'FR' (Fletcher-Reeves)
        rand_init: true                 # Random initialization helps escape local minima
        eps_values:                     
          L2: [1.0, 2.0]                # Common L2 perturbation budgets
          Linf: [8/255, 16/255]         # Common Linf perturbation budgets
      targeted:
        loss_fn: "cross_entropy"        # Loss function used (negated for targeted)
        steps: 60                       # More iterations for targeted
        alpha: 0.067                    # Step size (alpha = eps / (steps / 4) heuristic)
        alpha_multiplier: 40.0          # Alpha multiplier for Linf (gives ~2.5/255 step size)
        beta_method: "PR"               # Beta calculation
        rand_init: true                 # Random initialization helps escape local minima
        eps_values:
          L2: [2.0, 4.0]                # Larger L2 budgets for targeted
          Linf: [16/255, 32/255]        # Larger Linf budgets for targeted

    PGD:
      untargeted:
        loss_fn: "cross_entropy"   # Standard cross-entropy often more effective initially
        n_iterations: 40           # Standard iteration count
        step_size_linf: 2.5/255    # Slightly larger step size for Linf
        step_size_l2: 0.1          # Step size for L2 (eps / (steps / 4) heuristic approx)
        rand_init: true            # Use random start
        early_stopping: true       # Stop early if attack succeeds
        refine_steps: 0            # No refinement for untargeted by default
        use_binary_search_eps: false # No epsilon search for untargeted
        eps_values:
          Linf: [8/255]            # Standard Linf epsilon
          L2: [1.0, 2.0]           # Common L2 epsilons
      targeted:
        loss_fn: "carlini_wagner"  # CW loss often better for targeted
        n_iterations: 200          # More iterations needed for targeted
        step_size_linf: 2.5/255    # Slightly larger step size for Linf
        step_size_l2: 0.15         # Step size for L2
        rand_init: true            # Use random start
        early_stopping: true       # Stop early if attack succeeds
        refine_steps: 0           # Disable refinement until attack succeeds
        use_binary_search_eps: false # Disable eps search until attack succeeds
        eps_values:
          Linf: [16/255, 32/255]   # Larger Linf epsilons
          L2: [2.0, 3.0]           # Larger L2 epsilons

    LBFGS:
      untargeted:
        loss_fn: "cross_entropy"
        n_iterations: 50           # Standard from Zhu et al. (2019)
        history_size: 10           # Common value for L-BFGS memory
        line_search_fn: "armijo"   # Efficient line search
        max_line_search: 15        # Balance between precision and speed
        initial_step: 3.0          # Aggressive initial step size
        rand_init: true           # Random initialization
        init_std: 0.05            # Standard deviation for initialization
        grad_scale: 1.0           # No gradient scaling
        early_stopping: true      # Stop when attack succeeds
        eps_values:
          Linf: [8/255, 16/255]   # Standard bounds from literature
          L2: [1.0, 2.0]          # Common L2 bounds
      targeted:
        loss_fn: "cross_entropy"
        n_iterations: 100          # More iterations for targeted attacks
        history_size: 15           # Larger memory for better Hessian approximation
        line_search_fn: "strong_wolfe" # More precise line search
        max_line_search: 20        # More line search iterations
        initial_step: 2.0          # More conservative step size
        rand_init: true           # Random initialization
        init_std: 0.01            # Smaller initialization
        grad_scale: 1.5           # Slightly aggressive updates
        early_stopping: true      # Stop when attack succeeds
        eps_values:
          Linf: [16/255, 32/255]  # Larger bounds for targeted
          L2: [2.0, 4.0]          # Larger L2 bounds

# Target method configuration for targeted attacks
target_methods:
  random:
    description: "Select random target classes"
  least-likely:
    description: "Select least-likely predicted classes (hardest targets)"

# Tables configuration for reporting results
tables:
  table1:
    title: "Success Rates (%)"
    description: "Attack success rates per model"
  
  table2:
    title: "Perturbation Metrics" 
    description: "Measures of perturbation size and quality"
    metrics: ["l2_norm", "linf_norm", "ssim"]
  
  table3:
    title: "Computational Requirements"
    description: "Performance metrics for computational efficiency"
    metrics: ["iterations", "gradient_calls", "runtime"]
