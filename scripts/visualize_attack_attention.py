"""
Visualizes an original image and its Grad-CAM map alongside adversarial examples
and their CAM maps generated by specified attack methods in a grid layout.

Example Usage:
python scripts/visualize_attack_attention.py \
    --image_idx 176 \
    --model_name resnet18 \
    --attacks FGSM PGD CW \
    --output_path ./outputs/attack_attention_grid.png
"""

import torch
import torchvision.transforms as transforms

from PIL import Image
import matplotlib.pyplot as plt
import numpy as np

from pytorch_grad_cam import GradCAM
from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget
from pytorch_grad_cam.utils.image import show_cam_on_image
import argparse
import os
import sys
import collections
import yaml
import random  # For random target selection

# Add the project root to the path to import src
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from src.attacks import (
    FGSM,
    FFGSM,
    DeepFool,
    CW,
    PGD,
    CG,
)

# Import dataset and model loaders from src
from src.datasets.imagenet import get_dataset
from src.models.wrappers import get_model


# --- Configuration ---
def get_args():
    parser = argparse.ArgumentParser(
        description="Visualize Adversarial Attacks and Grad-CAM in a Grid (Untargeted vs Least-Likely CAM)"
    )
    parser.add_argument(
        "--image_idx",
        type=int,
        default=268,
        help="Index of the image in the dataset (default: 268 - a timber wolf)",
    )
    parser.add_argument(
        "--data_dir",
        type=str,
        default="./data",
        help="Directory containing the dataset (e.g., ./data/imagenet)",
    )
    parser.add_argument(
        "--model_name",
        type=str,
        default="resnet18",
        help="Name of the model (e.g., resnet18, vgg16)",
    )
    parser.add_argument(
        "--attacks",
        type=str,
        nargs="+",
        default=["FGSM", "FFGSM", "PGD", "CG", "CW", "DeepFool"],
        choices=["all", "FGSM", "FFGSM", "DeepFool", "CW", "PGD", "CG"],
        help="Which attacks to include in the grid ('all' or specific names)",
    )
    parser.add_argument(
        "--target_layer_path",
        type=str,
        default=None,
        help="Path to target layer (e.g., layer4[-1] for resnet). Auto-detect if None.",
    )
    parser.add_argument(
        "--output_path",
        type=str,
        default="./outputs/attack_attention_grid.png",
        help="Path to save the output visualization grid",
    )
    parser.add_argument(
        "--config-file",
        "-c",
        type=str,
        default="./config/config.yaml",
        help="Path to configuration file (defaults to config/config.yaml)",
    )
    args = parser.parse_args()
    return args


# Helper to parse fractions like in test scripts
def parse_fraction(value):
    """Parse string fractions like '4/255' or convert floats."""
    if isinstance(value, (int, float)):
        return float(value)
    if isinstance(value, str) and "/" in value:
        num, denom = value.split("/")
        try:
            return float(num) / float(denom)
        except ValueError:
            raise ValueError(f"Could not parse fraction: {value}")
    try:
        return float(value)
    except ValueError:
        raise ValueError(f"Could not parse value as float or fraction: {value}")


# --- Updated load_model function ---
def load_model(model_name, device):
    """Load model using the get_model wrapper."""
    print(f"Loading model: {model_name}...")
    try:
        model = get_model(model_name)
        model = model.to(device)
        model.eval()
        print("Model loaded successfully using get_model.")
        return model
    except Exception as e:
        print(f"Error loading model {model_name} using get_model: {e}")
        print(
            "Ensure the model name is correct and src modules are accessible (e.g., check imports and paths)."
        )
        exit(1)


def load_config(config_path):
    """Load configuration from YAML file."""
    if config_path is None:
        config_path = os.path.join(project_root, "config", "config.yaml")

    if not os.path.exists(config_path):
        raise FileNotFoundError(f"Configuration file not found at: {config_path}")

    print(f"Loading configuration from {config_path}")
    try:
        with open(config_path, "r") as f:
            config = yaml.safe_load(f)
        if config is None:
            raise ValueError("Config file is empty or invalid YAML.")
        return config
    except yaml.YAMLError as e:
        raise ValueError(f"Error parsing YAML file {config_path}: {e}")
    except Exception as e:
        raise RuntimeError(f"Unexpected error loading config {config_path}: {e}")


def create_attack_from_config(model, attack_type, config, mode="untargeted"):
    """
    Create an attack instance using parameters from the loaded config file.

    Args:
        model: The model to attack
        attack_type: Type of attack (e.g., "FGSM", "PGD")
        config: Configuration dictionary
        mode: Attack mode ("untargeted" or "targeted")

    Returns:
        An attack instance configured for the specified mode
    """
    print(f"  Attempting to load '{mode}' config for {attack_type}...")
    try:
        attack_params_all = config.get("attack", {}).get("params", {})
        if not attack_params_all:
            raise ValueError("Missing 'attack.params' section")
        if attack_type not in attack_params_all:
            raise ValueError(f"Config for '{attack_type}' not found")

        params = attack_params_all[attack_type].get(mode, None)
        if params is None:
            if len(attack_params_all[attack_type]) == 1:
                params = next(iter(attack_params_all[attack_type].values()))
                print(
                    f"    Warning: Using the only available config mode for {attack_type} as '{mode}'."
                )
            else:
                # Fallback to untargeted if targeted isn't available
                if (
                    mode == "targeted"
                    and "untargeted" in attack_params_all[attack_type]
                ):
                    print(
                        f"    Warning: No targeted config found for {attack_type}. Falling back to untargeted."
                    )
                    params = attack_params_all[attack_type]["untargeted"]
                else:
                    raise ValueError(f"Missing '{mode}' config for '{attack_type}'")

        print(f"    Loading config: {params}")
        attack = None
        if attack_type == "FGSM":
            # FGSM typically uses L-inf norm
            eps = parse_fraction(params["eps_values"]["Linf"][0])
            attack = FGSM(model=model, eps=eps)
        elif attack_type == "FFGSM":
            # FFGSM typically uses L-inf norm
            eps = parse_fraction(params["eps_values"]["Linf"][0])
            alpha = parse_fraction(params["alpha_linf"])
            attack = FFGSM(model=model, eps=eps, alpha=alpha)
        elif attack_type == "DeepFool":
            steps = int(params["steps"])
            overshoot = parse_fraction(params["overshoot_values"][0])
            top_k = int(params.get("top_k_classes", 10))
            attack = DeepFool(
                model=model, steps=steps, overshoot=overshoot, top_k_classes=top_k
            )
        elif attack_type == "CW":
            c = parse_fraction(params["c_init"])
            kappa = parse_fraction(params["confidence_values"][0])
            steps = int(params["steps"])
            lr = parse_fraction(params["learning_rate"])
            attack = CW(model=model, c=c, kappa=kappa, steps=steps, lr=lr)
        elif attack_type == "PGD":
            # Prefer Linf norm for PGD if available
            norm_config_key = params.get("norm", "Linf")
            if "eps_values" in params:
                if "Linf" in params["eps_values"]:
                    norm_config_key = "Linf"
                elif "L2" in params["eps_values"]:
                    norm_config_key = "L2"

            norm_internal = norm_config_key.upper()
            eps_values_dict = params.get("eps_values", {})
            if norm_config_key not in eps_values_dict:
                raise KeyError(f"eps_values -> {norm_config_key}")
            eps = parse_fraction(eps_values_dict[norm_config_key][0])
            steps = int(params["n_iterations"])
            step_size_key = f"step_size_{norm_config_key.lower()}"
            if step_size_key not in params:
                raise KeyError(step_size_key)
            step_size = parse_fraction(params[step_size_key])
            rand_init = params.get("rand_init", True)
            loss_fn = params.get("loss_fn", "cross_entropy")
            early_stopping = params.get("early_stopping", True)
            print(f"    Using {norm_internal} norm for PGD with eps={eps}")
            attack = PGD(
                model=model,
                norm=norm_internal,
                eps=eps,
                n_iterations=steps,
                step_size=step_size,
                rand_init=rand_init,
                loss_fn=loss_fn,
                early_stopping=early_stopping,
            )
        elif attack_type == "CG":
            # Prefer Linf norm for CG if available
            norm_config_key = params.get("norm", "L2")
            if "eps_values" in params:
                if "Linf" in params["eps_values"]:
                    norm_config_key = "Linf"
                elif "L2" in params["eps_values"]:
                    norm_config_key = "L2"

            norm_internal = norm_config_key.upper()
            eps_values_dict = params.get("eps_values", {})
            if norm_config_key not in eps_values_dict:
                raise KeyError(f"eps_values -> {norm_config_key}")
            eps = parse_fraction(eps_values_dict[norm_config_key][0])
            steps = int(params["steps"])
            alpha_key = f"alpha_{norm_config_key.lower()}"
            alpha = parse_fraction(params.get(alpha_key, params.get("alpha", 0.1)))
            beta_method = params.get("beta_method", "PR")
            rand_init = params.get("rand_init", False)
            print(f"    Using {norm_internal} norm for CG with eps={eps}")
            attack = CG(
                model=model,
                norm=norm_internal,
                eps=eps,
                steps=steps,
                alpha=alpha,
                beta_method=beta_method,
                rand_init=rand_init,
            )
        else:
            raise ValueError(f"Unknown attack type for config loading: {attack_type}")

        device = next(model.parameters()).device
        if hasattr(attack, "device"):
            attack.device = device
        elif hasattr(attack, "to"):
            attack = attack.to(device)

        # Set attack mode based on parameter
        if mode == "targeted":
            if hasattr(attack, "set_mode_targeted_least_likely"):
                print(f"    Setting attack to targeted least-likely mode")
                attack.set_mode_targeted_least_likely()
            else:
                raise ValueError(
                    f"Attack {attack_type} doesn't support targeted least-likely mode"
                )
        else:
            if hasattr(attack, "set_mode_default"):
                attack.set_mode_default()

        return attack
    except KeyError as e:
        raise ValueError(f"Missing key '{e}' in config for {attack_type} ({mode})")
    except Exception as e:
        raise RuntimeError(f"Error creating {attack_type} ({mode}): {e}")


def get_prediction(model, tensor, labels):
    """Gets top prediction: index, label string, confidence."""
    # Add check for tensor dimensions
    if tensor.dim() == 3:
        tensor = tensor.unsqueeze(0)  # Add batch dimension if missing

    with torch.no_grad():
        outputs = model(tensor)
        probabilities = torch.softmax(outputs, dim=1)
        top_prob, top_catid = torch.topk(probabilities, 1)

    pred_idx = top_catid.item()
    # Handle cases where labels might not cover all indices or is a dict
    if isinstance(labels, list):
        pred_label = labels[pred_idx] if pred_idx < len(labels) else f"Class {pred_idx}"
    elif isinstance(labels, dict):
        pred_label = labels.get(pred_idx, f"Class {pred_idx}")
    else:
        pred_label = f"Class {pred_idx}"  # Fallback

    pred_conf = top_prob.item() * 100
    return pred_idx, pred_label, pred_conf


def find_target_layer(model, model_name):
    """Finds a suitable target layer for Grad-CAM based on model type."""
    # Heuristics for common models (ensure this is robust)
    model_name_lower = model_name.lower()
    target_model = model  # Start with the potentially wrapped model
    if hasattr(model, "model"):  # Common wrapping pattern
        print("Model appears wrapped, accessing model.model for layer search.")
        target_model = model.model

    try:
        if "resnet" in model_name_lower:
            if hasattr(target_model, "layer4"):
                return [target_model.layer4[-1]]
            else:
                raise AttributeError("layer4 not found")
        elif "vgg" in model_name_lower:
            target_layer = None
            if hasattr(target_model, "features"):
                for layer in reversed(target_model.features):
                    if isinstance(layer, torch.nn.Conv2d):
                        target_layer = layer
                        break
            if target_layer is None:
                raise ValueError("Could not find Conv2d layer in VGG features")
            return [target_layer]
        elif "efficientnet" in model_name_lower:
            if hasattr(target_model, "features") and isinstance(
                target_model.features[-1], torch.nn.Sequential
            ):
                # Look for the last Conv2d within the final blocks/layers
                for block in reversed(target_model.features):
                    if isinstance(block, torch.nn.Sequential):
                        for layer in reversed(block):
                            # Check for ConvBNActivation structure common in EfficientNet
                            if hasattr(layer, "block") and isinstance(
                                layer.block[-1], torch.nn.Conv2d
                            ):  # Check last element in block
                                return [layer.block[-1]]
                            elif isinstance(layer, torch.nn.Conv2d):
                                return [layer]
            # Fallback if specific structure not found
            raise ValueError(
                f"Could not auto-detect EfficientNet target layer for {model_name}"
            )
        elif "mobilenet_v3" in model_name_lower:
            if hasattr(target_model, "features") and isinstance(
                target_model.features[-1], torch.nn.Sequential
            ):
                # MobileNetV3 structure can vary, try finding last Conv in last block
                for layer in reversed(target_model.features[-1]):
                    if hasattr(layer, "block"):  # Look inside ConvBNActivation blocks
                        for sub_layer in reversed(layer.block):
                            if isinstance(sub_layer, torch.nn.Conv2d):
                                return [sub_layer]
                    elif isinstance(layer, torch.nn.Conv2d):
                        return [layer]
            raise ValueError(
                f"Could not auto-detect MobileNetV3 target layer for {model_name}"
            )
        else:
            # Generic fallback (using target_model)
            target_layer = None
            for m in reversed(list(target_model.modules())):
                if isinstance(m, torch.nn.Conv2d):
                    target_layer = m
                    break
            if target_layer is None:
                raise ValueError(
                    f"Could not auto-detect a Conv2d target layer for {model_name}"
                )
            print(
                f"Warning: Auto-detected last Conv2d layer for {model_name}. This might not be the ideal target for Grad-CAM."
            )
            return [target_layer]

    except Exception as e:
        print(
            f"Error during target layer detection ({type(e).__name__}: {e}). Falling back to searching all modules."
        )
        # Generic fallback: find *any* last Conv2d in the original model object
        target_layer = None
        for m in reversed(list(model.modules())):  # Search original model here
            if isinstance(m, torch.nn.Conv2d):
                target_layer = m
                break
        if target_layer is None:
            raise ValueError(f"Could not find any Conv2d layer in {model_name}")
        print(f"Warning: Using generic fallback Conv2d layer: {target_layer}")
        return [target_layer]


def generate_cam(cam_method, input_tensor, target_class_idx):
    """Generates a grayscale CAM map for a given input and target class."""
    targets = [ClassifierOutputTarget(target_class_idx)]
    # Add check for tensor dimensions
    if input_tensor.dim() == 3:
        input_tensor = input_tensor.unsqueeze(0)

    grayscale_cam = cam_method(
        input_tensor=input_tensor, targets=targets, aug_smooth=True, eigen_smooth=True
    )
    if grayscale_cam is None:
        print("Warning: Grad-CAM returned None. Using a blank map.")
        # Get shape from input tensor
        h, w = input_tensor.shape[-2:]
        return np.zeros((h, w), dtype=np.float32)

    grayscale_cam = grayscale_cam[0, :]  # Get first image in batch
    return grayscale_cam


def denormalize_image(
    img_tensor, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)
):
    """Denormalizes a tensor image that is normalized."""
    # Ensure tensor is on CPU and detached for numpy conversion
    img_tensor_cpu = img_tensor.squeeze(0).cpu().clone().detach()

    mean = torch.tensor(mean, device=img_tensor_cpu.device).view(3, 1, 1)
    std = torch.tensor(std, device=img_tensor_cpu.device).view(3, 1, 1)

    denorm_tensor = img_tensor_cpu * std + mean
    # Convert back to numpy for visualization, permute dims, clip
    img_viz = denorm_tensor.permute(1, 2, 0).numpy()
    img_viz = np.clip(img_viz, 0, 1)
    return img_viz


# --- Updated Grid Visualization Function (2x2 Style) ---
def visualize_attack_grid(
    original_img_viz,
    original_pred_cam,
    original_least_likely_cam,
    original_label,
    original_conf,
    least_likely_label,
    attack_results,  # Dict: {attack_name: {untargeted: {...}, targeted: {...}}}
    output_path,
):
    """Creates and saves the 2x2 style grid visualization."""
    attack_names = list(attack_results.keys())
    num_attacks = len(attack_names)
    # Grid layout: Original Image + Untargeted CAMs | Original CAM + Targeted CAMs
    num_cols = 1 + num_attacks
    num_rows = 2

    # Configure matplotlib to use LaTeX for text rendering
    plt.rcParams.update(
        {
            "text.usetex": True,
            "font.family": "serif",
            "font.serif": ["Computer Modern Roman"],
            "font.size": 11,
            "axes.titlesize": 14,
            "axes.labelsize": 12,
        }
    )

    fig, axs = plt.subplots(
        num_rows, num_cols, figsize=(num_cols * 2.5, num_rows * 3)
    )  # Adjusted figsize

    # Ensure axs is always 2D array
    if num_cols == 1:
        axs = axs.reshape(num_rows, 1)
    elif num_rows == 1:
        axs = axs.reshape(1, num_cols)  # Should be num_rows=2 here

    # --- Top-Left: Original Image ---
    axs[0, 0].imshow(original_img_viz.astype(np.float32))
    orig_label_latex = r"\texttt{{{}}}".format(
        original_label.replace("_", " ").replace("%", r"\%")
    )
    axs[0, 0].set_title(
        r"Original\\Pred: {} ({:.1f}\%) ".format(orig_label_latex, original_conf)
    )
    axs[0, 0].axis("off")

    # --- Bottom-Left: Original CAM (Least Likely Target) ---
    try:
        orig_ll_cam_img = show_cam_on_image(
            original_img_viz.astype(np.float32), original_least_likely_cam, use_rgb=True
        )
    except Exception as e:
        print(f"Error overlaying original CAM: {e}. Displaying CAM map only.")
        orig_ll_cam_img = original_least_likely_cam
    axs[1, 0].imshow(orig_ll_cam_img)
    ll_label_latex = r"\texttt{{{}}}".format(
        least_likely_label.replace("_", " ").replace("%", r"\%")
    )
    axs[1, 0].set_title(r"Orig. CAM\\Target: {}".format(ll_label_latex))
    axs[1, 0].axis("off")

    # --- Top-Right Sequence: Untargeted CAMs ---
    for i, name in enumerate(attack_names):
        col_idx = i + 1
        result_untargeted = attack_results[name].get("untargeted", {})
        adv_img_untargeted_viz = result_untargeted.get(
            "img", original_img_viz
        )  # Image needed for overlay
        adv_cam_untargeted = result_untargeted.get(
            "cam", np.zeros_like(original_pred_cam)
        )
        adv_label_untargeted = result_untargeted.get("label", "Untargeted Fail")
        adv_conf_untargeted = result_untargeted.get("conf", 0.0)
        adv_label_latex = r"\texttt{{{}}}".format(
            adv_label_untargeted.replace("_", " ").replace("%", r"\%")
        )

        try:
            cam_overlay_untargeted = show_cam_on_image(
                adv_img_untargeted_viz.astype(np.float32),
                adv_cam_untargeted,
                use_rgb=True,
            )
        except Exception as e:
            print(f"Error overlaying Untargeted CAM for {name}: {e}.")
            cam_overlay_untargeted = adv_cam_untargeted  # Fallback

        axs[0, col_idx].imshow(cam_overlay_untargeted)
        axs[0, col_idx].set_title(
            r"{} (U)\\{} ({:.1f}\%) ".format(
                name.replace("_", " "), adv_label_latex, adv_conf_untargeted
            )
        )
        axs[0, col_idx].axis("off")

    # --- Bottom-Right Sequence: Least-Likely Target CAMs ---
    for i, name in enumerate(attack_names):
        col_idx = i + 1
        result_targeted = attack_results[name].get("targeted", {})
        adv_img_targeted_viz = result_targeted.get("img", original_img_viz)
        adv_cam_targeted = result_targeted.get("cam", np.zeros_like(original_pred_cam))
        adv_label_targeted = result_targeted.get("label", "Targeted Fail")
        adv_conf_targeted = result_targeted.get("conf", 0.0)
        target_label = result_targeted.get("target_label", "N/A")

        if adv_cam_targeted is not None and not np.all(adv_cam_targeted == 0):
            try:
                cam_overlay_targeted = show_cam_on_image(
                    adv_img_targeted_viz.astype(np.float32),
                    adv_cam_targeted,
                    use_rgb=True,
                )
            except Exception as e:
                print(f"Error overlaying Targeted CAM for {name}: {e}.")
                cam_overlay_targeted = adv_cam_targeted
            axs[1, col_idx].imshow(cam_overlay_targeted)
            adv_label_latex = r"\texttt{{{}}}".format(
                adv_label_targeted.replace("_", " ").replace("%", r"\%")
            )
            axs[1, col_idx].set_title(
                r"{} Grad-CAM (T)\\{} ({:.1f}\%) ".format(
                    name.replace("_", " "), adv_label_latex, adv_conf_targeted
                )
            )
            axs[1, col_idx].axis("off")
        else:
            target_label_latex = r"\texttt{{{}}}".format(
                target_label.replace("_", " ").replace("%", r"\%")
            )
            axs[1, col_idx].text(
                0.5,
                0.5,
                f"Targeted N/A\nTarget: {target_label_latex}",
                ha="center",
                va="center",
                fontsize=10,
                color="gray",
            )
            axs[1, col_idx].axis("off")

    plt.tight_layout(pad=0.5, h_pad=1.5, w_pad=0.5)  # Adjust padding

    # Create output directory if it doesn't exist
    output_dir = os.path.dirname(output_path)
    if output_dir:
        os.makedirs(output_dir, exist_ok=True)

    # Save
    plt.savefig(output_path, facecolor="white", bbox_inches="tight", dpi=200)
    print(f"Visualization grid saved to {output_path}")
    plt.close(fig)


# --- End Grid Visualization Function ---


# --- Helper functions for target selection ---
def get_random_target_label(original_label_idx, num_classes):
    """Selects a random target class different from the original."""
    target_label_idx = original_label_idx
    while target_label_idx == original_label_idx:
        target_label_idx = random.randint(0, num_classes - 1)
    return target_label_idx


def get_least_likely_target_label(model, input_tensor):
    """Selects the class with the lowest prediction probability."""
    # Ensure input tensor has batch dimension
    if input_tensor.dim() == 3:
        input_tensor = input_tensor.unsqueeze(0)

    with torch.no_grad():
        outputs = model(input_tensor)
        probabilities = torch.softmax(outputs, dim=1)
        least_likely_idx = torch.argmin(probabilities, dim=1).item()
    return least_likely_idx


# --- Main Execution ---
if __name__ == "__main__":
    global args
    args = get_args()
    model_name = args.model_name

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")

    # Load Configuration
    try:
        config = load_config(args.config_file)
    except (FileNotFoundError, ValueError, RuntimeError) as e:
        print(f"Configuration Error: {e}")
        exit(1)

    # 1. Load Model
    model = load_model(args.model_name, device)

    # 2. Load Dataset
    print(f"Loading dataset from: {args.data_dir}")
    num_classes = 0
    try:
        dataset = get_dataset("imagenet", data_dir=args.data_dir, max_samples=None)
        print(f"Dataset loaded. Total images: {len(dataset)}")
        num_classes = (
            len(dataset.class_names) if hasattr(dataset, "class_names") else 1000
        )  # Default to 1000 for ImageNet
        if args.image_idx >= len(dataset):
            raise IndexError(
                f"Error: image_idx {args.image_idx} out of bounds ({len(dataset)} images)."
            )
        input_tensor, true_label_idx = dataset[args.image_idx]
        input_tensor = input_tensor.to(device)
        if input_tensor.dim() == 3:
            input_tensor = input_tensor.unsqueeze(0)
    except Exception as e:
        print(f"Error loading dataset/image index {args.image_idx}: {e}")
        exit(1)

    # 3. Get Class Names
    try:
        labels = dataset.class_names
        if not labels:
            raise ValueError("Class names not found.")
    except Exception as e:
        print(f"Error getting class names: {e}")
        labels = [f"Class {i}" for i in range(num_classes)]

    # 4. Get Visualization Image
    try:
        vis_image_path = None
        if hasattr(dataset, "image_paths") and args.image_idx < len(
            dataset.image_paths
        ):
            candidate_path = dataset.image_paths[args.image_idx]
            if isinstance(candidate_path, str):
                vis_image_path = candidate_path
        elif hasattr(dataset, "samples") and args.image_idx < len(dataset.samples):
            candidate_path = dataset.samples[args.image_idx][0]
            if isinstance(candidate_path, str):
                vis_image_path = candidate_path

        if vis_image_path and os.path.exists(vis_image_path):
            print(f"Loading image for visualization from: {vis_image_path}")
            vis_pil = Image.open(vis_image_path).convert("RGB")
            vis_preprocess = transforms.Compose(
                [
                    transforms.Resize(256),
                    transforms.CenterCrop(224),
                    transforms.ToTensor(),
                ]
            )
            original_img_viz = vis_preprocess(vis_pil).permute(1, 2, 0).numpy()
        else:
            # Fallback message logic
            if vis_image_path:
                print(
                    f"Warning: Visualization image path {vis_image_path} not found. Using denormalized tensor."
                )
            else:
                print(
                    "Warning: Could not determine visualization image path. Using denormalized tensor."
                )
            original_img_viz = denormalize_image(input_tensor.cpu())
    except Exception as e:
        print(f"Error loading image for visualization: {e}. Using denormalized tensor.")
        original_img_viz = denormalize_image(input_tensor.cpu())

    # 5. Original Prediction
    original_idx, original_label, original_conf = get_prediction(
        model, input_tensor, labels
    )
    print(
        f"Original Prediction: {original_label} ({original_conf:.1f}%) - Index: {original_idx}"
    )
    if original_idx != true_label_idx:
        print(
            f"Warning: Model prediction ({original_label}/{original_idx}) != Dataset label ({true_label_idx})."
        )

    # --- Attack Setup ---
    attacks_to_run = collections.OrderedDict()
    attack_choices = args.attacks
    attack_class_map = {
        "FGSM": FGSM,
        "FFGSM": FFGSM,
        "DeepFool": DeepFool,
        "CW": CW,
        "PGD": PGD,
        "CG": CG,
    }
    if "all" in attack_choices:
        selected_attack_names = list(attack_class_map.keys())
    else:
        selected_attack_names = [a for a in attack_choices if a in attack_class_map]
    if not selected_attack_names:
        print("Error: No valid attacks selected.")
        exit(1)

    # --- CAM Setup ---
    try:
        # (CAM setup logic as before - find target layers, instantiate cam_instance)
        if args.target_layer_path:
            try:  # Simplified resolver
                layer_parts = args.target_layer_path.replace("]", "").split("[")
                target_module = model
                # ... (rest of resolver logic) ...
                target_layers = [target_module]
            except Exception as e:
                print(f"Error resolving target_layer_path: {e}. Auto-detecting.")
                target_layers = find_target_layer(model, args.model_name)
        else:
            target_layers = find_target_layer(model, args.model_name)
        if not target_layers:
            raise ValueError("Could not determine target layers.")
        print(
            f"Using target layer(s) for Grad-CAM: {[type(layer).__name__ for layer in target_layers]}"
        )
        cam_instance = GradCAM(model=model, target_layers=target_layers)
        print("Generating Grad-CAM for original image...")
        original_pred_cam = generate_cam(cam_instance, input_tensor, original_idx)
        original_least_likely_cam = generate_cam(
            cam_instance,
            input_tensor,
            get_least_likely_target_label(model, input_tensor),
        )
    except Exception as e:
        print(f"Error during CAM setup/original CAM: {e}")
        import traceback

        traceback.print_exc()
        exit(1)

    # --- Run Attacks and Generate Adversarial Data ---
    attack_results_data = collections.OrderedDict()
    max_attempts_per_attack = 3

    # Get the least likely target class once for consistency
    least_likely_idx = get_least_likely_target_label(model, input_tensor)
    least_likely_label = (
        labels[least_likely_idx]
        if least_likely_idx < len(labels)
        else f"Class {least_likely_idx}"
    )
    print(
        f"Least likely target class: {least_likely_label} (Index: {least_likely_idx})"
    )

    for attack_name in selected_attack_names:
        print(f"--- Processing Attack: {attack_name} ---")
        attack_results_data[attack_name] = {}  # Initialize dict for this attack

        # --- Untargeted Attack ---
        print("  Running Untargeted attack...")
        untargeted_attack_obj = None
        adv_tensor_untargeted = None
        adv_label_untargeted = "Untargeted Fail"
        adv_conf_untargeted = 0.0
        adv_idx_untargeted = original_idx
        adv_img_viz_untargeted = original_img_viz  # Placeholder
        adv_cam_untargeted = np.zeros_like(original_pred_cam)  # Placeholder

        try:
            untargeted_attack_obj = create_attack_from_config(
                model, attack_name, config
            )
            # Retry logic for untargeted
            for attempt in range(max_attempts_per_attack):
                print(
                    f"    Untargeted Attempt {attempt + 1}/{max_attempts_per_attack}..."
                )
                attempt_successful = False
                try:
                    if attempt > 0:  # Adjust params
                        print("      Adjusting untargeted parameters...")
                        # (Parameter adjustment logic as before using untargeted_attack_obj)
                        if hasattr(untargeted_attack_obj, "eps"):
                            setattr(
                                untargeted_attack_obj,
                                "eps",
                                min(
                                    getattr(untargeted_attack_obj, "eps") * 1.5,
                                    16 / 255,
                                ),
                            )
                            print(
                                f"        eps->{getattr(untargeted_attack_obj,'eps'):.4f}"
                            )
                        if hasattr(untargeted_attack_obj, "steps"):
                            setattr(
                                untargeted_attack_obj,
                                "steps",
                                min(getattr(untargeted_attack_obj, "steps") * 2, 200),
                            )
                            print(
                                f"        steps->{getattr(untargeted_attack_obj,'steps')}"
                            )
                        if hasattr(untargeted_attack_obj, "n_iterations"):
                            setattr(
                                untargeted_attack_obj,
                                "n_iterations",
                                min(
                                    getattr(untargeted_attack_obj, "n_iterations") * 2,
                                    200,
                                ),
                            )
                            print(
                                f"        n_iter->{getattr(untargeted_attack_obj,'n_iterations')}"
                            )
                        if hasattr(untargeted_attack_obj, "c") and attack_name == "CW":
                            setattr(
                                untargeted_attack_obj,
                                "c",
                                min(getattr(untargeted_attack_obj, "c") * 2, 100),
                            )
                            print(
                                f"        CW c->{getattr(untargeted_attack_obj,'c'):.2f}"
                            )

                    # Generate untargeted example
                    true_label_tensor = torch.tensor([true_label_idx]).to(device)
                    current_adv_tensor = untargeted_attack_obj(
                        input_tensor, true_label_tensor
                    )

                    if current_adv_tensor is None:
                        print("    Attack returned None.")
                        break
                    else:
                        current_adv_idx, current_adv_label, current_adv_conf = (
                            get_prediction(model, current_adv_tensor, labels)
                        )
                        print(
                            f"      Attempt {attempt+1} Pred: {current_adv_label} ({current_adv_conf:.1f}%)"
                        )
                        if current_adv_idx != original_idx:  # Success
                            print(
                                f"      Untargeted successful on attempt {attempt + 1}!"
                            )
                            attempt_successful = True
                            adv_idx_untargeted = current_adv_idx
                            adv_label_untargeted = current_adv_label
                            adv_conf_untargeted = current_adv_conf
                            adv_tensor_untargeted = current_adv_tensor
                        elif (
                            attempt == max_attempts_per_attack - 1
                        ):  # Last failed attempt
                            print(
                                f"      Untargeted failed after {max_attempts_per_attack} attempts. Storing last result."
                            )
                            adv_idx_untargeted = current_adv_idx
                            adv_label_untargeted = current_adv_label
                            adv_conf_untargeted = current_adv_conf
                            adv_tensor_untargeted = current_adv_tensor
                except Exception as e:
                    print(f"    Error during untargeted attempt {attempt+1}: {e}")
                    import traceback

                    traceback.print_exc()
                    break
                if attempt_successful:
                    break

            # Generate CAM for final untargeted result
            if adv_tensor_untargeted is not None:
                print("    Generating CAM for untargeted result...")
                adv_cam_untargeted = generate_cam(
                    cam_instance, adv_tensor_untargeted, adv_idx_untargeted
                )
                adv_img_viz_untargeted = denormalize_image(adv_tensor_untargeted)
            else:  # Keep placeholders if tensor is None
                adv_img_viz_untargeted = original_img_viz
                adv_cam_untargeted = np.zeros_like(original_pred_cam)

        except (ValueError, RuntimeError, KeyError) as e:
            print(f"  Failed to initialize/run untargeted {attack_name}: {e}")
        except Exception as e:
            print(f"  Unexpected error during untargeted {attack_name}: {e}")
            import traceback

            traceback.print_exc()

        attack_results_data[attack_name]["untargeted"] = {
            "img": adv_img_viz_untargeted,
            "cam": adv_cam_untargeted,
            "label": adv_label_untargeted,
            "conf": adv_conf_untargeted,
        }

        # --- Targeted Attack ---
        print("  Running Targeted attack...")
        targeted_attack_obj = None
        adv_tensor_targeted = None
        adv_label_targeted = "Targeted Fail"
        adv_conf_targeted = 0.0
        adv_idx_targeted = original_idx
        adv_img_viz_targeted = original_img_viz  # Placeholder
        adv_cam_targeted = np.zeros_like(original_pred_cam)  # Placeholder

        try:
            # Special handling for CG - try both L2 and Linf with exact config params
            if attack_name == "CG":
                print(
                    "    Using special CG targeted attack strategy with multiple attempts and different norms"
                )

                # Store original config
                attack_params_all = config.get("attack", {}).get("params", {})
                cg_params = attack_params_all["CG"]["targeted"]

                # Track best attack across all attempts
                best_adv_tensor = None
                best_adv_idx = None
                best_adv_label = None
                best_adv_conf = 0.0
                best_distance_to_target = float(
                    "inf"
                )  # Track how close we get to target

                # Try each norm type from config (prioritize Linf)
                norm_types = []
                if "Linf" in cg_params["eps_values"]:
                    norm_types.append("Linf")
                if "L2" in cg_params["eps_values"]:
                    norm_types.append("L2")

                if not norm_types:
                    print(
                        "    No valid norm types found in config for CG targeted attack"
                    )
                    continue

                print(f"    Trying norms in order: {norm_types}")

                for norm_type in norm_types:
                    # Try each epsilon value from config (largest to smallest for targeted attacks)
                    eps_values = [
                        parse_fraction(eps)
                        for eps in cg_params["eps_values"][norm_type]
                    ]
                    eps_values.sort(
                        reverse=True
                    )  # Try largest epsilon first for targeted attacks

                    for eps in eps_values:
                        print(f"\n    Trying CG with {norm_type} norm, eps={eps}")

                        # Create attack with exact config parameters
                        alpha = parse_fraction(cg_params.get("alpha", 0.067))
                        if norm_type == "Linf" and "alpha_multiplier" in cg_params:
                            alpha_multiplier = parse_fraction(
                                cg_params["alpha_multiplier"]
                            )
                            alpha = alpha * alpha_multiplier
                            print(f"    Adjusted alpha for Linf: {alpha:.4f}")

                        steps = int(cg_params["steps"])
                        beta_method = cg_params.get("beta_method", "PR")

                        print(
                            f"    Creating CG attack with: norm={norm_type}, eps={eps}, steps={steps}, alpha={alpha:.4f}, beta={beta_method}"
                        )
                        cg_attack = CG(
                            model=model,
                            norm=norm_type,
                            eps=eps,
                            steps=steps,
                            alpha=alpha,
                            beta_method=beta_method,
                            rand_init=True,  # Always use random init for targeted
                        )

                        # Set to targeted mode
                        cg_attack.set_mode_targeted_least_likely()

                        # Try with default settings
                        true_label_tensor = torch.tensor([true_label_idx]).to(device)
                        try:
                            print(f"    Running attack with {steps} steps...")
                            current_adv_tensor = cg_attack(
                                input_tensor, true_label_tensor
                            )

                            if current_adv_tensor is not None:
                                current_adv_idx, current_adv_label, current_adv_conf = (
                                    get_prediction(model, current_adv_tensor, labels)
                                )
                                print(
                                    f"    Result: {current_adv_label} ({current_adv_conf:.1f}%)"
                                )

                                # Check if this is better than previous attempts
                                if current_adv_idx == least_likely_idx:
                                    print(
                                        f"    Success! Found target class {least_likely_label}"
                                    )
                                    best_adv_tensor = current_adv_tensor
                                    best_adv_idx = current_adv_idx
                                    best_adv_label = current_adv_label
                                    best_adv_conf = current_adv_conf
                                    break  # Exit epsilon loop on success
                                else:
                                    # Calculate logit distance to target class to track progress
                                    with torch.no_grad():
                                        logits = model(current_adv_tensor)
                                        target_logit = logits[
                                            0, least_likely_idx
                                        ].item()
                                        pred_logit = logits[0, current_adv_idx].item()
                                        distance = pred_logit - target_logit

                                        if distance < best_distance_to_target:
                                            print(
                                                f"    New best attempt (closer to target): {current_adv_label}"
                                            )
                                            best_distance_to_target = distance
                                            best_adv_tensor = current_adv_tensor
                                            best_adv_idx = current_adv_idx
                                            best_adv_label = current_adv_label
                                            best_adv_conf = current_adv_conf
                            else:
                                print("    Attack returned None")

                        except Exception as e:
                            print(
                                f"    Error during CG attack with {norm_type}, eps={eps}: {e}"
                            )
                            continue

                    if best_adv_idx == least_likely_idx:
                        break  # Exit norm loop if we found target

                # Use the best result found
                if best_adv_tensor is not None:
                    print(
                        f"    Using best CG result: {best_adv_label} ({best_adv_conf:.1f}%)"
                    )
                    adv_tensor_targeted = best_adv_tensor
                    adv_idx_targeted = best_adv_idx
                    adv_label_targeted = best_adv_label
                    adv_conf_targeted = best_adv_conf
                else:
                    print("    All CG targeted attempts failed")
            else:
                # Regular logic for other attacks
                targeted_attack_obj = create_attack_from_config(
                    model, attack_name, config, mode="targeted"
                )

                # Retry logic for other attacks (unchanged)
                for attempt in range(max_attempts_per_attack):
                    print(
                        f"    Targeted Attempt {attempt + 1}/{max_attempts_per_attack}..."
                    )
                    attempt_successful = False
                    try:
                        if attempt > 0:
                            print(
                                "      Attempting with next epsilon value if available..."
                            )
                            # Instead of hard-coded adjustments, try to get next epsilon from config
                            attack_params_all = config.get("attack", {}).get(
                                "params", {}
                            )
                            if (
                                attack_name in attack_params_all
                                and "targeted" in attack_params_all[attack_name]
                            ):
                                params = attack_params_all[attack_name]["targeted"]

                                # For attacks that use epsilon
                                if hasattr(targeted_attack_obj, "eps"):
                                    current_eps = getattr(targeted_attack_obj, "eps")
                                    norm_type = getattr(
                                        targeted_attack_obj, "norm", "Linf"
                                    ).upper()

                                    # Get all epsilon values for this norm
                                    if (
                                        "eps_values" in params
                                        and norm_type in params["eps_values"]
                                    ):
                                        eps_values = [
                                            parse_fraction(eps)
                                            for eps in params["eps_values"][norm_type]
                                        ]
                                        eps_values.sort()  # Ensure they're in ascending order

                                        # Find next larger epsilon
                                        next_eps = None
                                        for eps in eps_values:
                                            if eps > current_eps:
                                                next_eps = eps
                                                break

                                        # If found, use it
                                        if next_eps is not None:
                                            setattr(
                                                targeted_attack_obj, "eps", next_eps
                                            )
                                            print(
                                                f"        Using next epsilon: {next_eps:.6f}"
                                            )

                                # For CW attack
                                if (
                                    hasattr(targeted_attack_obj, "c")
                                    and attack_name == "CW"
                                ):
                                    current_c = getattr(targeted_attack_obj, "c")
                                    # Double c, using existing config practice
                                    next_c = current_c * 2
                                    setattr(targeted_attack_obj, "c", next_c)
                                    print(f"        CW c->{next_c:.2f}")

                                # For iterative attacks
                                if hasattr(targeted_attack_obj, "steps") or hasattr(
                                    targeted_attack_obj, "n_iterations"
                                ):
                                    steps_attr = (
                                        "steps"
                                        if hasattr(targeted_attack_obj, "steps")
                                        else "n_iterations"
                                    )
                                    current_steps = getattr(
                                        targeted_attack_obj, steps_attr
                                    )

                                    # Increment steps from config if available, otherwise just double
                                    step_increments = params.get("step_increments", [2])
                                    if step_increments and len(step_increments) > 0:
                                        multiplier = (
                                            step_increments[0]
                                            if isinstance(
                                                step_increments[0], (int, float)
                                            )
                                            else 2
                                        )
                                        next_steps = int(current_steps * multiplier)
                                        setattr(
                                            targeted_attack_obj, steps_attr, next_steps
                                        )
                                        print(f"        {steps_attr}->{next_steps}")

                        # For targeted attacks with least-likely mode
                        true_label_tensor = torch.tensor([true_label_idx]).to(device)
                        current_adv_tensor = targeted_attack_obj(
                            input_tensor, true_label_tensor
                        )

                        if current_adv_tensor is None:
                            print("    Targeted attack returned None.")
                            break
                        else:
                            current_adv_idx, current_adv_label, current_adv_conf = (
                                get_prediction(model, current_adv_tensor, labels)
                            )
                            print(
                                f"      Attempt {attempt+1} Pred: {current_adv_label} ({current_adv_conf:.1f}%)"
                            )
                            # Check if prediction matches the least likely class (our target)
                            if (
                                current_adv_idx == least_likely_idx
                            ):  # Success - matches target
                                print(
                                    f"      Targeted successful on attempt {attempt + 1}!"
                                )
                                attempt_successful = True
                                adv_idx_targeted = current_adv_idx
                                adv_label_targeted = current_adv_label
                                adv_conf_targeted = current_adv_conf
                                adv_tensor_targeted = current_adv_tensor
                            elif (
                                attempt == max_attempts_per_attack - 1
                            ):  # Last failed attempt
                                print(
                                    f"      Targeted failed after {max_attempts_per_attack} attempts. Storing last result if different from original."
                                )
                                # Store even if not successful for visualization
                                adv_idx_targeted = current_adv_idx
                                adv_label_targeted = current_adv_label
                                adv_conf_targeted = current_adv_conf
                                adv_tensor_targeted = current_adv_tensor
                    except Exception as e:
                        print(f"    Error during targeted attempt {attempt+1}: {e}")
                        import traceback

                        traceback.print_exc()
                        break
                    if attempt_successful:
                        break

            # Generate CAM for final targeted result - show even failed attempts
            if adv_tensor_targeted is not None:
                print("    Generating CAM for targeted result...")
                adv_cam_targeted = generate_cam(
                    cam_instance, adv_tensor_targeted, adv_idx_targeted
                )
                adv_img_viz_targeted = denormalize_image(adv_tensor_targeted)
            else:
                print(
                    "    No targeted result to generate CAM for (attack returned None)."
                )
                adv_img_viz_targeted = original_img_viz
                adv_cam_targeted = np.zeros_like(original_pred_cam)

        except (ValueError, RuntimeError, KeyError) as e:
            print(f"  Failed to initialize/run targeted {attack_name}: {e}")
        except Exception as e:
            print(f"  Unexpected error during targeted {attack_name}: {e}")
            import traceback

            traceback.print_exc()

        attack_results_data[attack_name]["targeted"] = {
            "img": adv_img_viz_targeted,
            "cam": adv_cam_targeted,
            "label": adv_label_targeted,
            "conf": adv_conf_targeted,
            "target_label": least_likely_label,
        }

    # --- Final Visualization ---
    print("Generating final visualization grid...")
    try:
        # Call the updated visualization function with the string label
        visualize_attack_grid(
            original_img_viz,
            original_pred_cam,
            original_least_likely_cam,
            original_label,
            original_conf,
            least_likely_label,
            attack_results_data,
            args.output_path,
        )
    except Exception as e:
        print(f"Error during final visualization: {e}")
        import traceback

        traceback.print_exc()

    print("Done.")


def load_config(config_path):
    """Load configuration from YAML file."""
    # Default path if not provided
    if config_path is None:
        config_path = os.path.join(project_root, "config", "config.yaml")

    if not os.path.exists(config_path):
        raise FileNotFoundError(f"Configuration file not found at: {config_path}")

    print(f"Loading configuration from {config_path}")
    try:
        with open(config_path, "r") as f:
            config = yaml.safe_load(f)
        if config is None:
            raise ValueError("Config file is empty or invalid YAML.")
        return config
    except yaml.YAMLError as e:
        raise ValueError(f"Error parsing YAML file {config_path}: {e}")
    except Exception as e:
        raise RuntimeError(f"Unexpected error loading config {config_path}: {e}")


# --- End Target Selection Helpers ---
