# Configuration for adversarial attack method evaluation

# Dataset configuration
dataset:
  name: "imagenet"
  num_images: 5    # Number of images to evaluate per model
  image_dir: "data"

# Model configuration
models:
  - "resnet18"     # Standard baseline model
  - "resnet50"     # Deeper variant of ResNet
  - "vgg16"        # Standard CNN architecture
  - "efficientnet" # Modern efficient architecture
  - "mobilenet"    # Lightweight architecture

# Evaluation parameters
evaluation:
  save_results: true
  output_dir: "results"

# Attack method configuration
attack:
  method: "DeepFool"  # Options: FGSM, FFGSM, DeepFool, CW, MIFGSM, PGD
  norm_types:
    - "Linf" 
    - "L2"
  
  # Method-specific parameters
  params:
    FGSM:
      untargeted:
        loss_fn: "cross_entropy"
        eps_values:
          Linf: [4/255, 8/255]  # Standard values from Goodfellow et al. (2014)
          L2: [0.5, 1.0]        # Standard values for L2 attacks
      targeted:
        loss_fn: "cross_entropy"
        eps_values:
          Linf: [16/255, 32/255]  # Larger values needed for targeted attacks
          L2: [2.0, 3.0]         # Larger perturbations for targeted attacks

    FFGSM:
      untargeted:
        loss_fn: "cross_entropy"
        alpha_linf: 0.4   # Standard value from Wong et al. (2020)
        alpha_l2: 0.25    # Standard value for L2 norm
        eps_values:
          Linf: [8/255]   # Should achieve ~87.5% success with SSIM > 0.8
          L2: [0.5]       # Should achieve good success with SSIM > 0.7
      targeted:
        loss_fn: "cross_entropy"
        alpha_linf: 0.5   # Increased alpha for targeted attacks
        alpha_l2: 0.35    # Increased alpha for targeted attacks
        eps_values:
          Linf: [16/255, 32/255]  # Larger epsilon for targeted attacks
          L2: [2.0, 3.0]          # Larger epsilon for targeted attacks
    
    PGD:
      untargeted:
        loss_fn: "cross_entropy"
        n_iterations: 40           # Standard value from Madry et al. (2017)
        alpha_init_linf: 2/255     # Step size for Linf (1/10 of epsilon)
        alpha_init_l2: 0.1         # Step size for L2
        alpha_type: "diminishing"  # Step size scheduling
        rand_init: true            # Random initialization
        early_stopping: true       # Stop when attack succeeds
        eps_values:
          Linf: [8/255]            # Standard value from Madry et al. (2017)
          L2: [1.0, 2.0]           # Common values for L2 PGD
      targeted:
        loss_fn: "cross_entropy"
        n_iterations: 100          # More iterations for targeted attacks
        alpha_init_linf: 2/255     # Step size for Linf (smaller relative to eps)
        alpha_init_l2: 0.15        # Slightly larger step size for targeted
        alpha_type: "constant"     # Constant step size works better for targeted
        rand_init: true            # Random initialization
        early_stopping: true       # Stop when attack succeeds
        eps_values:
          Linf: [16/255, 32/255]   # Larger values for targeted attacks
          L2: [2.0, 3.0]           # Larger values for targeted attacks
    
    DeepFool:
      # DeepFool is typically untargeted only
      untargeted:
        num_classes: 1000          # ImageNet class count
        overshoot_values: [0.02]   # Standard value from Moosavi-Dezfooli et al. (2016)
        steps: 50                  # Reduced from 100 as DeepFool converges quickly
        early_stopping: true       # Enable early stopping to improve efficiency
        top_k_classes: 10          # Only consider top-k classes for efficiency
    
    CW:
      untargeted:
        confidence_values: [0.0]   # Standard value from Carlini & Wagner (2017)
        c_init: 1.0                # Initial c value
        steps: 100                 # Standard number of iterations for untargeted
        learning_rate: 0.01        # Standard learning rate from original paper
        abort_early: true          # Enable early stopping for efficiency
      targeted:
        confidence_values: [20.0]  # Higher confidence for targeted attacks
        c_init: 10.0               # Higher c value for targeted attacks
        steps: 200                 # More iterations for targeted attacks
        learning_rate: 0.01        # Same learning rate
        abort_early: true          # Enable early stopping for efficiency

    MIFGSM:
      untargeted:
        loss_fn: "cross_entropy"   # Standard loss function
        steps: 10                  # Standard iterations from Dong et al. (2018)
        alpha: 0.01                # Standard step size per iteration
        decay_factor: 0.9          # Standard momentum value (renamed from momentum)
        eps_values:
          Linf: [8/255]            # Standard value for imperceptible attacks
          L2: [0.5]                # Standard value for balanced attacks
      targeted:
        loss_fn: "cross_entropy"   # Standard loss function
        steps: 20                  # More iterations for targeted attacks 
        alpha: 0.01                # Same step size
        decay_factor: 0.9          # Same momentum value
        eps_values:
          Linf: [16/255, 32/255]   # Larger epsilon for targeted attacks
          L2: [2.0, 3.0]           # Larger epsilon for targeted attacks

# Target method configuration for targeted attacks
target_methods:
  random:
    description: "Select random target classes"
  least-likely:
    description: "Select least-likely predicted classes (hardest targets)"

# Tables configuration for reporting results
tables:
  table1:
    title: "Success Rates (%)"
    description: "Attack success rates per model"
  
  table2:
    title: "Perturbation Metrics" 
    description: "Measures of perturbation size and quality"
    metrics: ["l2_norm", "linf_norm", "ssim"]
  
  table3:
    title: "Computational Requirements"
    description: "Performance metrics for computational efficiency"
    metrics: ["iterations", "gradient_calls", "runtime"]
